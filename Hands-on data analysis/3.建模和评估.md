任务一：切割训练集和测试集
这里使用留出法划分数据集

将数据集分为自变量和因变量
按比例切割训练集和测试集(一般测试集的比例有30%、25%、20%、15%和10%)
使用分层抽样
设置随机种子以便结果能复现

任务提示1
切割数据集是为了后续能评估模型泛化能力
sklearn中切割数据集的方法为train_test_split
查看函数文档可以在jupyter noteboo里面使用train_test_split?后回车即可看到
分层和随机种子在参数里寻找

任务二：模型创建
创建基于线性模型的分类模型（逻辑回归）
创建基于树的分类模型（决策树、随机森林）
分别使用这些模型进行训练，分别的到训练集和测试集的得分
查看模型的参数，并更改参数值，观察模型变化
提示2
逻辑回归不是回归模型而是分类模型，不要与LinearRegression混淆
随机森林其实是决策树集成为了降低决策树过拟合的情况
线性模型所在的模块为sklearn.linear_model
树模型所在的模块为sklearn.ensemble

任务三：输出模型预测结果
输出模型预测分类标签
输出不同分类标签的预测概率
提示3
一般监督模型在sklearn里面有个predict能输出预测标签，predict_proba则可以输出标签概率


模型评估
模型评估是为了知道模型的泛化能力。
交叉验证（cross-validation）是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。
在交叉验证中，数据被多次划分，并且需要训练多个模型。
最常用的交叉验证是 k 折交叉验证（k-fold cross-validation），其中 k 是由用户指定的数字，通常取 5 或 10。
准确率（precision）度量的是被预测为正例的样本中有多少是真正的正例
召回率（recall）度量的是正类样本中有多少被预测为正类
f-分数是准确率与召回率的调和平均
